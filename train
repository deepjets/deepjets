#!/usr/bin/env python


def train_one_point(gpu_id, model_name, files, learning_rate, batch_size):
    import theano.sandbox.cuda
    theano.sandbox.cuda.use(gpu_id)
    from deepjets.learning import cross_validate_model
    from deepjets.models import get_maxout
    import numpy as np

    model = get_maxout(25**2)
    vals = cross_validate_model(
        model, files,
        model_name=model_name + "_{0}_lr{1}_bs{2}".format(gpu_id, learning_rate, batch_size),
        batch_size=batch_size, epochs=100,
        val_frac=0.1, patience=10,
        lr_init=learning_rate, lr_scale_factor=1.0,
        log_to_file=True, read_into_ram=True, max_jobs=1)  # do not run CV in parallel
    return np.array(vals['AUC']).mean()


class ObjectiveFunction(object):
    def __init__(self, num_gpu, model_name, train_files):
        self.num_gpu = num_gpu
        self.model_name = model_name
        self.train_files = train_files
        self.cmd = ('THEANO_FLAGS=device=gpu{gpu},floatX=float32 ./train_one_point '
                    '--name {name} --learning-rate {learning_rate} --batch-size {batch_size} {files}')

    def __call__(self, args):
        from deepjets.parallel import map_pool, FuncWorker

        print map_pool(
            FuncWorker, [(train_one_point, 'gpu{0}'.format(igpu), self.model_name, self.train_files, learning_rate, batch_size) for igpu, (learning_rate, batch_size) in enumerate(args[:4])],
            n_jobs=4)


def bayesian_optimization(model_name, train_files):
    import GPyOpt
    from numpy.random import seed
    seed(12345)

    domain = [
        {'name': 'learning_rate', 'type': 'continuous', 'domain': (0.0001, 0.001)},
        {'name': 'batch_size', 'type': 'discrete', 'domain': (32, 1024)}] 
    objective = ObjectiveFunction(4, model_name, train_files)
    bo = GPyOpt.methods.BayesianOptimization(f=objective, domain=domain, exact_feval=True)
    bo.run_optimization(max_iter=100, eps=10e-6)


if __name__ == '__main__':

    from argparse import ArgumentParser

    parser = ArgumentParser()
    parser.add_argument('--sig', dest='signal_file')
    parser.add_argument('--bkg', dest='background_file')
    parser.add_argument('--name')
    parser.add_argument('--nfolds', type=int, default=5)
    parser.add_argument('--test-fraction', type=float, default=0.2)
    args = parser.parse_args()

    from deepjets.utils import prepare_datasets
    from deepjets.path_utils import mkdir_p
    
    mkdir_p('datasets')
    mkdir_p('models')

    dataset_name = 'datasets/' + args.name
    model_name = 'models/' + args.name
    
    # Prepare datasets once for all trainings
    h5_files = prepare_datasets(
        args.signal_file, args.background_file, dataset_name,
        test_frac=args.test_fraction, n_folds=args.nfolds,
        shuffle=True, balance=True)

    bayesian_optimization(args.name, h5_files['train'])
