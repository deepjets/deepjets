#!/usr/bin/env python

def imgify(filename, pix_size, image_size, zoom, auto_zoom, suffix, multi, location):
    import os
    import sys
    import numpy as np
    from deepjets.preprocessing import preprocess, pixel_edges
    from deepjets.utils import jet_mass
    from deepjets.multi_progress import Writer
    from progressbar import Bar, ETA, Percentage, FormatLabel, ProgressBar
    import h5py
    
    # read from the events file
    h5_input = h5py.File(filename, 'r')
    dset_jet = h5_input['jet']
    dset_trimmed_jet = h5_input['trimmed_jet']
    dset_subjets = h5_input['subjets']
    dset_trimmed_constit = h5_input['trimmed_constituents']
    dset_shrinkage = h5_input['shrinkage']
    dset_dr_subjets = h5_input['subjet_dr']
    dset_tau_1 = h5_input['tau_1']
    dset_tau_2 = h5_input['tau_2']
    dset_tau_3 = h5_input['tau_3']

    jet_size = h5_input['jet_size'][0]
    subjet_size_fraction = h5_input['subjet_size_fraction'][0]
    
    eta, phi = pix_size.split(',')
    eta_size = float(eta) 
    phi_size = float(phi)

    edges = pixel_edges(
        jet_size=jet_size,
        subjet_size_fraction=subjet_size_fraction,
        pix_size=(eta_size, phi_size))
    eta_edges, phi_edges = edges

    # create the output file
    output = os.path.splitext(filename)[0]
    if suffix:
        output += '_{0}'.format(suffix)
    output += '_images.h5'
    h5_output = h5py.File(output, 'w')
    dset_images = h5_output.create_dataset(
        'images', (len(dset_subjets), image_size, image_size), dtype=np.double)

    auxvars_arrays = [
        dset_jet['pT'], dset_trimmed_jet['pT'],
        dset_jet['mass'], dset_trimmed_jet['mass'],
        dset_dr_subjets[:], dset_tau_1[:], dset_tau_2[:], dset_tau_3[:]]
    auxvars_names = 'pt,pt_trimmed,mass,mass_trimmed,subjet_dr,tau_1,tau_2,tau_3'

    if 'weights' in h5_input:
        auxvars_arrays.append(h5_input['weights'][:])
        auxvars_names += ',weights'
    
    auxvars = np.core.records.fromarrays(auxvars_arrays, names=auxvars_names)
    dset_auxvars = h5_output.create_dataset('auxvars', auxvars.shape, auxvars.dtype)
    dset_auxvars[:] = auxvars

    dset_eta_edges = h5_output.create_dataset(
        'eta_edges', (1, 2), dtype=np.double)
    dset_phi_edges = h5_output.create_dataset(
        'phi_edges', (1, 2), dtype=np.double)

    dset_eta_edges[0] = (eta_edges[0], eta_edges[-1])
    dset_phi_edges[0] = (phi_edges[0], phi_edges[-1])

    widgets = [FormatLabel(output), ' ', Percentage(), ' ', Bar('>'), ' ', ETA()]
    writer = Writer(location) if multi else sys.stderr
    pbar = ProgressBar(fd=writer, widgets=widgets, max_value=len(dset_subjets)).start()
    for i, event in enumerate(xrange(len(dset_subjets))):
        subjets = dset_subjets[event]
        trimmed_constit = dset_trimmed_constit[event]
        if auto_zoom:
            actual_size = 2 * 80.385 / dset_jet[event]['pT'];
            zoom_factor = jet_size / actual_size 
        else:
            zoom_factor = 1. / dset_shrinkage[event] if zoom else False
        image = preprocess(subjets, trimmed_constit, edges,
                           zoom=zoom_factor,
                           normalize=True,
                           out_width=image_size)
        # save the jet mass, pT and image
        dset_images[event] = image
        pbar.update(i)
    pbar.finish()
    h5_output.close()


if __name__ == '__main__':
    from argparse import ArgumentParser

    parser = ArgumentParser()
    parser.add_argument('--jobs', '-n', type=int, default=-1)
    parser.add_argument('--pix-size', default='0.1,0.1')
    parser.add_argument('--image-size', type=int, default=25)
    parser.add_argument('--no-zoom', default=False, action='store_true')
    # temp feature requested by James:
    parser.add_argument('--auto-zoom', default=False, action='store_true')
    parser.add_argument('--suffix', default=None)
    parser.add_argument('files', nargs='+')
    args = parser.parse_args()
    
    from deepjets.parallel import map_pool, FuncWorker
    from deepjets.multi_progress import term
    from contextlib import contextmanager

    @contextmanager                                                                 
    def do_nothing(*args, **kwargs):                                                
        yield
    
    multi = len(args.files) > 1 and args.jobs != 1 
    context = term.fullscreen if multi else do_nothing
    
    with context():
        map_pool(
            FuncWorker,
            [(imgify, filename,
            args.pix_size, args.image_size, not args.no_zoom, args.auto_zoom, args.suffix,
            multi, (0, i)) for i, filename in enumerate(args.files)],
            n_jobs=args.jobs)
